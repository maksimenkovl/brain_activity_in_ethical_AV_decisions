{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a08b6a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import dirname, join as pjoin\n",
    "import scipy.io as spio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "import matplotlib.pyplot as plt\n",
    "import os, fnmatch\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52543bd",
   "metadata": {},
   "source": [
    "This script downloads protocol files containing the moments when each scene starts and button is pressed and brain data files containing ERSP evolutions at each EEG sensor for all scenes in three frequency bands (theta, alpha, and beta).\n",
    "\n",
    "We perform the following steps:\n",
    "\n",
    "1) for each subject, we aggregate ERSP over time between the scene start and button press using median value.\n",
    "2) we exclude scenes with large ERSP values using z-score threshold.\n",
    "3) we aggregate ERSP over all remaining scenes using median value.\n",
    "\n",
    "As a result, for each subject we have ERSP values at each EEG sensor (all sensors are defined by the file 'EEG_SENSOR_NAMES.xlsx')\n",
    "\n",
    "Note, that same procedure is done for three frequency bands: theta, alpha, and beta\n",
    "Note, that this script contains the procedure for Picture-based scenes. Same procedure should be done for Video-based scenes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2dd26a",
   "metadata": {},
   "source": [
    "# Reading Protocol and ERSP Files from Directory (Picture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2674eaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "protocol_files=[]\n",
    "listOfFiles = os.listdir('.')  \n",
    "pattern = \"*_Text.xlsx\"  \n",
    "for entry in listOfFiles:  \n",
    "    if fnmatch.fnmatch(entry, pattern):\n",
    "        res = entry.split('_')\n",
    "        res.append(entry)\n",
    "        protocol_files.append(res)\n",
    "protocol_files=sorted(protocol_files, key=itemgetter(2))\n",
    "\n",
    "data_files_alpha=[]\n",
    "import os, fnmatch\n",
    "listOfFiles = os.listdir('.')  \n",
    "pattern = \"*alpha_Text.mat\"  \n",
    "for entry in listOfFiles:  \n",
    "    if fnmatch.fnmatch(entry, pattern):\n",
    "        res = entry.split('_')\n",
    "        res.append(entry)\n",
    "        data_files_alpha.append(res)\n",
    "data_files_alpha=sorted(data_files_alpha, key=itemgetter(0))\n",
    "\n",
    "data_files_theta=[]\n",
    "import os, fnmatch\n",
    "listOfFiles = os.listdir('.')  \n",
    "pattern = \"*theta_Text.mat\"  \n",
    "for entry in listOfFiles:  \n",
    "    if fnmatch.fnmatch(entry, pattern):\n",
    "        res = entry.split('_')\n",
    "        res.append(entry)\n",
    "        data_files_theta.append(res)\n",
    "data_files_theta=sorted(data_files_theta, key=itemgetter(0))\n",
    "\n",
    "data_files_beta=[]\n",
    "import os, fnmatch\n",
    "listOfFiles = os.listdir('.')  \n",
    "pattern = \"*beta_Text.mat\"  \n",
    "for entry in listOfFiles:  \n",
    "    if fnmatch.fnmatch(entry, pattern):\n",
    "        res = entry.split('_')\n",
    "        res.append(entry)\n",
    "        data_files_beta.append(res)\n",
    "data_files_beta=sorted(data_files_beta, key=itemgetter(0))\n",
    "\n",
    "channels=pd.read_excel('EEG_SENSOR_NAMES.xlsx')\n",
    "ch=channels.channels.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e02d29b",
   "metadata": {},
   "source": [
    "# Aggregating ERSP Data over the time of trial using median value (Picture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca00204c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ALPHA=pd.DataFrame()\n",
    "for k in range(len(protocol_files)):\n",
    "    \n",
    "    participant = protocol_files[k][2]\n",
    "    protocol_file=protocol_files[k][4]\n",
    "    data_alpha=data_files_alpha[k][3]\n",
    "    \n",
    "    mat = spio.loadmat(data_alpha)\n",
    "    aa=mat['alpha_']\n",
    "    \n",
    "    protocol=pd.read_excel(protocol_file)\n",
    "    RT=protocol['BP Latency']-protocol['SS Latency']\n",
    "    \n",
    "    matrix = np.zeros((aa.shape[0],aa.shape[1]))\n",
    "    for i in range(aa.shape[1]):\n",
    "        for j in range(aa.shape[0]):\n",
    "            matrix[j,i]=np.median(aa[j,i,0:int(RT[0])])\n",
    "\n",
    "    df = pd.DataFrame(matrix,columns=ch) \n",
    "    for cname in ch:\n",
    "        df = df[abs(stats.zscore(df[cname]))< 3]\n",
    "    df['participant']=int(participant)\n",
    "    DATA_ALPHA = pd.concat([DATA_ALPHA,df])  \n",
    "\n",
    "DATA_BETA=pd.DataFrame()\n",
    "for k in range(len(protocol_files)):\n",
    "    \n",
    "    participant = protocol_files[k][2]\n",
    "    protocol_file=protocol_files[k][4]\n",
    "    data_beta=data_files_beta[k][3]\n",
    "    \n",
    "    mat = spio.loadmat(data_beta)\n",
    "    aa=mat['beta_']\n",
    "    \n",
    "    protocol=pd.read_excel(protocol_file)\n",
    "    RT=protocol['BP Latency']-protocol['SS Latency']\n",
    "    \n",
    "    matrix = np.zeros((aa.shape[0],aa.shape[1]))\n",
    "    for i in range(aa.shape[1]):\n",
    "        for j in range(aa.shape[0]):\n",
    "            matrix[j,i]=np.median(aa[j,i,0:int(RT[0])])\n",
    "\n",
    "    df = pd.DataFrame(matrix,columns=ch) \n",
    "    for cname in ch:\n",
    "        df = df[abs(stats.zscore(df[cname]))< 3]\n",
    "    df['participant']=int(participant)\n",
    "    DATA_BETA = pd.concat([DATA_BETA,df])  \n",
    "\n",
    "DATA_THETA=pd.DataFrame()\n",
    "for k in range(len(protocol_files)):\n",
    "    \n",
    "    participant = protocol_files[k][2]\n",
    "    protocol_file=protocol_files[k][4]\n",
    "    data_theta=data_files_theta[k][3]\n",
    "    \n",
    "    mat = spio.loadmat(data_theta)\n",
    "    aa=mat['theta_']\n",
    "    \n",
    "    protocol=pd.read_excel(protocol_file)\n",
    "    RT=protocol['BP Latency']-protocol['SS Latency']\n",
    "    \n",
    "    matrix = np.zeros((aa.shape[0],aa.shape[1]))\n",
    "    for i in range(aa.shape[1]):\n",
    "        for j in range(aa.shape[0]):\n",
    "            matrix[j,i]=np.median(aa[j,i,0:int(RT[0])])\n",
    "\n",
    "    df = pd.DataFrame(matrix,columns=ch) \n",
    "    for cname in ch:\n",
    "        df = df[abs(stats.zscore(df[cname]))< 3]\n",
    "    df['participant']=int(participant)\n",
    "    DATA_THETA = pd.concat([DATA_THETA,df]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbbe0d3",
   "metadata": {},
   "source": [
    "# Aggregating ERSP across trials using median value (Picture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "333481fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_THETA_AV=pd.DataFrame()\n",
    "for participant in DATA_THETA['participant'].unique():\n",
    "    df=DATA_THETA[DATA_THETA['participant']==participant]\n",
    "    d2=df[ch].median()\n",
    "    d=pd.DataFrame(d2).T\n",
    "    d.columns=ch\n",
    "    d['participant']=participant\n",
    "    DATA_THETA_AV=pd.concat([DATA_THETA_AV,d])\n",
    "\n",
    "DATA_ALPHA_AV=pd.DataFrame()\n",
    "for participant in DATA_ALPHA['participant'].unique():\n",
    "    df=DATA_ALPHA[DATA_ALPHA['participant']==participant]\n",
    "    d2=df[ch].median()\n",
    "    d=pd.DataFrame(d2).T\n",
    "    d.columns=ch\n",
    "    d['participant']=participant\n",
    "    DATA_ALPHA_AV=pd.concat([DATA_ALPHA_AV,d])\n",
    "\n",
    "DATA_BETA_AV=pd.DataFrame()\n",
    "for participant in DATA_BETA['participant'].unique():\n",
    "    df=DATA_BETA[DATA_BETA['participant']==participant]\n",
    "    d2=df[ch].median()\n",
    "    d=pd.DataFrame(d2).T\n",
    "    d.columns=ch\n",
    "    d['participant']=participant\n",
    "    DATA_BETA_AV=pd.concat([DATA_BETA_AV,d])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e53afd",
   "metadata": {},
   "source": [
    "# Export Subject-specific ERSP Data (Picture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bbb36f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ALPHA_AV.to_csv('ERSP_TEXT_ALPHA.csv')\n",
    "DATA_BETA_AV.to_csv('ERSP_TEXT_BETA.csv')\n",
    "DATA_THETA_AV.to_csv('ERSP_TEXT_THETA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26487f13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
